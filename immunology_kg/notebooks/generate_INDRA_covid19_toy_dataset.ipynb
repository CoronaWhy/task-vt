{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script Overview\n",
    "This script creates a toy dataset from INDRA covid19, hosted on emma.indra.bio \n",
    "\n",
    "Emma puts together this graph on daily basis via a cron job that pulls in literature, does NER,  train new ML model..\n",
    "It incorporates daily updates from CORD-19 and also searches the Internet, and runs about 6 text mining systems on those\n",
    "\n",
    "The script converts the graph to BEL format via pybel library. \n",
    "The pybel library can be used to further process the graph and generate toy dataset outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0,\"/home/lani_lichtenstein/indra/\")\n",
    "print(sys.path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pykeen\n",
    "import torch\n",
    "from pykeen.pipeline import pipeline\n",
    "import pybel\n",
    "import pybel_tools\n",
    "import indra\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(time.asctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(getpass.getuser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(indra.__path__) # check using local installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pybel.get_version(with_git_hash=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import requests\n",
    "#from indra.statements import stmts_from_json\n",
    "#from indra.tools import assemble_corpus as ac\n",
    "#from indra.assemblers.pybel import PybelAssembler\n",
    "#model_url = 'https://emmaa.s3.amazonaws.com/assembled/covid19/latest_statements_covid19.json'\n",
    "#stmts_json = requests.get(model_url).json()\n",
    "#stmts = stmts_from_json(stmts_json)\n",
    "#filtered_stmts = ac.filter_belief(stmts, 0.9)\n",
    "#pa = PybelAssembler(filtered_stmts)\n",
    "#pybel_graph = pa.make_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pybel.io.emmaa import get_statements_from_emmaa\n",
    "from indra.tools import assemble_corpus as ac\n",
    "from indra.assemblers.pybel import PybelAssembler\n",
    "\n",
    "stmts = get_statements_from_emmaa('covid19')\n",
    "filtered_stmts = ac.filter_belief(stmts, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filtered_stmts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from indra.assemblers.html.assembler import _format_evidence_text\n",
    "from tqdm import tqdm\n",
    "from indra.statements import Evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore filtered statements \n",
    "filtered_stmts_with_nlp_evidence=[]\n",
    "for st in tqdm(filtered_stmts):\n",
    "    \n",
    "    #print(type(st.evidence[0].text)) # each statement has a list of objects of type Evidence https://indra.readthedocs.io/en/latest/_modules/indra/statements/evidence.html\n",
    "\n",
    "            \n",
    "    statement_evidence =_format_evidence_text(st)\n",
    "    for i, statement_evidence_tmp in enumerate(statement_evidence):\n",
    "            #st.evidence[i][\"text_annotated\"]=statement_evidence_tmp\n",
    "        evjson=st.evidence[i].to_json()                \n",
    "        evjson['annotations']['text_nlp']=statement_evidence_tmp # create new dict element in annotations    \n",
    "        evobj=Evidence._from_json(evjson)\n",
    "        st.evidence[i] = evobj\n",
    "\n",
    "    filtered_stmts_with_nlp_evidence.append(st)        \n",
    "    # explore evidence\n",
    "    # evjson=st.evidence[0].to_json()\n",
    "    # evannotations=evjson['annotations']\n",
    "    # for key in evannotations.keys():\n",
    "     #   print(key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st=filtered_stmts_with_nlp_evidence[0]\n",
    "x=st.evidence[0].to_json()\n",
    "for key in x.keys():\n",
    "    print(key)\n",
    "print(\"\\n\")\n",
    "y=x['annotations']\n",
    "for key in y.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for st in filtered_stmts_with_nlp_evidence:\n",
    "    x=st.evidence[0].to_json()['annotations']\n",
    "    for key in x.keys():\n",
    "        print(key)\n",
    "    #print(x[\"text_nlp\"])\n",
    "    \n",
    "        print(\"new \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa = PybelAssembler(filtered_stmts_with_nlp_evidence)\n",
    "pybel_graph = pa.make_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Indra graph to Pybel\n",
    "#https://emmaa.indra.bio/dashboard/covid19?tab=model\n",
    "\n",
    "#pybel_covid_graph=pybel.from_emmaa('covid19', date=\"2020-04-23-17-44-57\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pybel_graph.summarize() # summarise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(pybel_graph, open( \"pybel_graph.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach B - Generate Toy Dataset with Raw Text and Evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use local repo cloned from github to access to_triple function\n",
    "# this is not yet in pypi version, so need to access local cloned location\n",
    "#sys.path.insert(0,\"/home/username/pybel/src/\") # If you are using a local version of the file\n",
    "\n",
    "#from pybel.io.triples import api\n",
    "# not working - IGNORE\n",
    "#import imp\n",
    "#imp.find_module(\"pybel\")\n",
    "#triples_api = imp.load_source('api', \"/home/lani_lichtenstein/pybel/src/pybel/io/triples/api.py\")\n",
    "#import importlib\n",
    "#importlib.reload(pybel)\n",
    "pybel.__path__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pybel_graph=pickle.load(open( \"pybel_graph.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pybel.dsl import BaseConcept\n",
    "from tqdm import tqdm\n",
    "uniq_key_list_annotations=[]\n",
    "\n",
    "for u,v,data in tqdm(pybel_graph.edges(data=True)):\n",
    "            \n",
    "    if 'annotations' in data.keys():\n",
    "        #print(\"Explore relation \\n\")\n",
    "        #print(data['relation'])\n",
    "        #print(\"\\n\")\n",
    "        annotations=data['annotations']\n",
    "        #print(annotations)\n",
    "        \n",
    "        for key in annotations.keys():\n",
    "            if key not in uniq_key_list_annotations:\n",
    "                uniq_key_list_annotations.append(key)\n",
    "                \n",
    "        #for key,val in annotations.items():\n",
    "        #    print(key)\n",
    "        #    print(type(annotations[key]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniq_key_list_annotations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pybel.dsl import BaseConcept\n",
    "from tqdm import tqdm\n",
    "#from pybel.io.triples import api\n",
    "\n",
    "uniq_key_list_annotations=[]\n",
    "column_list=[\"Source\", \"Target\", \"Relation\", \"Evidence\", \"Citation\", \"Text_NLP\"]\n",
    "indra_df=pd.DataFrame(columns=column_list)\n",
    "\n",
    "for u,v,data in tqdm(pybel_graph.edges(data=True)):\n",
    "\n",
    "    source='NaN'\n",
    "    target='NaN'\n",
    "    evidence='NaN'\n",
    "    relation='NaN'\n",
    "    annotations='NaN'\n",
    "    text_nlp='NaN'\n",
    "    \n",
    "    #h,r,t=to_triple(u,v,data) https://github.com/pybel/pybel/blob/master/src/pybel/io/triples/api.py\n",
    "    \n",
    "    if isinstance(u, BaseConcept):\n",
    "        source=u.name\n",
    "        #source_obo=u.obo\n",
    "        #print(entity)\n",
    "        #print(u.name)\n",
    "        #print(u.obo)\n",
    "        #print(\"\\n\")\n",
    "        \n",
    "    if isinstance(v, BaseConcept):\n",
    "        target=v.name\n",
    "        \n",
    "    if 'evidence' in data.keys():  # look also at pybel.has_edge_evidence() \n",
    "        #print(\"Explore evidence \\n\")\n",
    "        #print(data['evidence'])\n",
    "        evidence=data[\"evidence\"]\n",
    "        #print(type(evidence))\n",
    "    \n",
    "    if 'relation' in data.keys():\n",
    "        #print(\"Explore relation \\n\")\n",
    "        #print(data['relation'])\n",
    "        #print(\"\\n\")\n",
    "        relation=data['relation']\n",
    "        \n",
    "    if 'annotations' in data.keys():\n",
    "        #print(\"Explore relation \\n\")\n",
    "        #print(data['relation'])\n",
    "        #print(\"\\n\")\n",
    "        annotations=data['annotations']\n",
    "        #print(annotations)\n",
    "        \n",
    "        for key in annotations.keys():\n",
    "            if key not in uniq_key_list_annotations:\n",
    "                uniq_key_list_annotations.append(key)\n",
    "        \n",
    "        if 'evidence_annotations' in annotations.keys():\n",
    "            evidence_annotations=annotations['evidence_annotations']\n",
    "            if 'text_nlp' in evidence_annotations.keys():\n",
    "                text_nlp=evidence_annotations['text_nlp']\n",
    "            \n",
    "    if 'citation' in data.keys():\n",
    "        #print(\"Explore relation \\n\")\n",
    "        #print(data['relation'])\n",
    "        #print(\"\\n\")\n",
    "        citation=data['citation']\n",
    "        \n",
    "    tmp=pd.Series([source, target, relation, evidence, citation, text_nlp], index=column_list)\n",
    "    indra_df=indra_df.append(tmp, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(indra_df, open( \"indra_df.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get text position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "indra_df=pickle.load(open( \"indra_df.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore\n",
    "indra_df.shape\n",
    "indra_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.5/en_core_sci_md-0.2.5.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import scispacy\n",
    "import en_core_sci_md\n",
    "from spacy.matcher import Matcher\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# correct code\n",
    "# nlp=spacy.load(\"en_core_sci_md\")\n",
    "\n",
    "# problem with not recognising path\n",
    "nlp=spacy.load(\"/home/lani_lichtenstein/.local/lib/python3.6/site-packages/en_core_sci_md/en_core_sci_md-0.2.5/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if using dask to process\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client\n",
    "\n",
    "client = Client(threads_per_worker=4, n_workers=1)\n",
    "client\n",
    "indra_dd=dd.from_pandas(indra_df,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@dask.delayed\n",
    "def get_text_position(txt_nlp, position_flag):\n",
    "    ''' Function get cell position for source, target start and stop'''\n",
    "    \n",
    "    matcher = Matcher(nlp.vocab, validate=True)\n",
    "\n",
    "    nlp_doc = txt_nlp\n",
    "    new_doc = txt_nlp.text\n",
    "    new_doc_nlp=[]\n",
    "\n",
    "    names = []\n",
    "    \n",
    "    if position_flag== 0: # source start\n",
    "        pattern = [{\"TEXT\": {\"REGEX\": \"<\"}}, {\"TEXT\": \"span\"}, {\"TEXT\": \"class=\\\"badge\"}, {\"TEXT\": \"badge-subject\\\"\"},{\"TEXT\": {\"REGEX\": \">\"}}]\n",
    "    elif position_flag == 1:\n",
    "        pattern = [{\"TEXT\": {\"REGEX\": \"<\"}}, {\"TEXT\": \"/span\"}, {\"TEXT\": \">\"}]\n",
    "    elif position_flag == 2:\n",
    "        pattern = [{\"TEXT\": {\"REGEX\": \"<\"}}, {\"TEXT\": \"span\"}, {\"TEXT\": \"class=\\\"badge\"}, {\"TEXT\": \"badge-object\\\"\"},{\"TEXT\": {\"REGEX\": \">\"}}]\n",
    "    elif position_flag == 3:\n",
    "        pattern = [{\"TEXT\": {\"REGEX\": \"<\"}}, {\"TEXT\": \"/span\"}, {\"TEXT\": \">\"}]\n",
    "\n",
    "    matcher.add('source_start', None, pattern) \n",
    "    matches = matcher(nlp_doc) \n",
    "\n",
    "    for match_id, start, end in matches[0:1]: # just use first match \n",
    "        span = nlp_doc[start:end] \n",
    "        names.append(span.text) \n",
    "\n",
    "    for name in names: \n",
    "        new_doc = new_doc.replace(name,'',1) # replace first instance only\n",
    "        new_doc = new_doc.replace('  ',' ') # replace double whitespace with one whitespace\n",
    "        new_doc = new_doc.replace('  ',' ') # replace double whitespace with one whitespace\n",
    "        new_doc_nlp=nlp(new_doc)\n",
    "    \n",
    "    return(matches,new_doc_nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if using dask\n",
    "#get_text_position=dask.delayed(get_text_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indra_df_new=indra_df.copy()\n",
    "\n",
    "indra_df_new['source_start']=np.NaN\n",
    "indra_df_new['source_end']=np.NaN\n",
    "indra_df_new['target_start']=np.NaN\n",
    "indra_df_new['target_end']=np.NaN\n",
    "indra_df_new['annotation_text']=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## process each row - adds new columns for source, target start and end\n",
    "# also add in new column for TxtNLP which is different to Evidence text\n",
    "\n",
    "for i in tqdm(range(indra_df.shape[0])): \n",
    "    #print(i)\n",
    "\n",
    "    if indra_df.Text_NLP[i]==\"NaN\" or 'text' not in indra_df.Text_NLP[i].keys():\n",
    "        continue\n",
    "        \n",
    "    txt=indra_df.Text_NLP[i]['text']\n",
    "            \n",
    "    source_start=np.NaN\n",
    "    source_end=np.NaN\n",
    "    target_start=np.NaN\n",
    "    target_end=np.NaN\n",
    "\n",
    "    if txt == None:\n",
    "        continue    \n",
    "    txt=txt.replace(\"</span>\", \" </span> \") # so tokenizer can split the makrker of the source/target span into separate token\n",
    "    txt_nlp=nlp(txt)\n",
    "    evidence_nlp=nlp(indra_df.Evidence[i])\n",
    "\n",
    "    \n",
    "    # Two cases - source appears first, target appears first. \n",
    "    matches,new_doc_nlp=get_text_position(txt_nlp=txt_nlp,position_flag=0) # source start\n",
    "    #matches,new_doc_nlp=get_text_position(txt_nlp=txt_nlp,position_flag=0).compute() # dask, source start\n",
    "    if len(matches) > 0:\n",
    "        source_start=matches[0][1]\n",
    "    matches,new_doc_nlp=get_text_position(txt_nlp=txt_nlp,position_flag=2) # source start\n",
    "    if len(matches) > 0:\n",
    "        target_start=matches[0][1]\n",
    "\n",
    "    if source_start < target_start:\n",
    "        option_start=\"A\"\n",
    "    else:\n",
    "        option_start=\"B\"\n",
    "    \n",
    "    if option_start == \"A\":\n",
    "        \n",
    "        # get source start\n",
    "        if txt_nlp==[]: # empty list\n",
    "            continue\n",
    "        matches,new_doc_nlp=get_text_position(txt_nlp=txt_nlp,position_flag=0)\n",
    "        if len(matches) > 0:\n",
    "            source_start=matches[0][1]\n",
    "\n",
    "        # get source end \n",
    "        if new_doc_nlp==[]:\n",
    "            continue\n",
    "        matches,new_doc_nlp=get_text_position(txt_nlp=new_doc_nlp,position_flag=1)\n",
    "        if len(matches) > 0:\n",
    "            source_end=matches[0][1] \n",
    "\n",
    "        # get target start\n",
    "        if new_doc_nlp==[]:\n",
    "            continue\n",
    "        matches,new_doc_nlp=get_text_position(txt_nlp=new_doc_nlp,position_flag=2) # get target start\n",
    "        if len(matches) > 0:\n",
    "            target_start=matches[0][1]\n",
    "\n",
    "        # get target end\n",
    "        if new_doc_nlp==[]:\n",
    "            continue\n",
    "        matches,new_doc_nlp=get_text_position(txt_nlp=new_doc_nlp,position_flag=3)\n",
    "        if len(matches) > 0:\n",
    "            target_end=matches[0][1]\n",
    "\n",
    "        if new_doc_nlp==[]:\n",
    "            continue\n",
    "\n",
    "        \n",
    "    if option_start == \"B\": # target appears before source in text\n",
    "\n",
    "        # get target start\n",
    "        if txt_nlp==[]: # empty list\n",
    "            continue\n",
    "        matches,new_doc_nlp=get_text_position(txt_nlp=txt_nlp,position_flag=2) # pick up target pattern\n",
    "        if len(matches) > 0:\n",
    "            target_start=matches[0][1]\n",
    "\n",
    "        # get target end \n",
    "        if new_doc_nlp==[]:\n",
    "            continue\n",
    "        matches,new_doc_nlp=get_text_position(txt_nlp=new_doc_nlp,position_flag=3) # pick up '</span>' to end target\n",
    "        if len(matches) > 0:\n",
    "            target_end=matches[0][1]\n",
    "\n",
    "        # get source start\n",
    "        if new_doc_nlp==[]:\n",
    "            continue\n",
    "        matches,new_doc_nlp=get_text_position(txt_nlp=new_doc_nlp,position_flag=0) # get source start\n",
    "        if len(matches) > 0:\n",
    "            source_start=matches[0][1]\n",
    "\n",
    "        # get source end\n",
    "        if new_doc_nlp==[]:\n",
    "            continue\n",
    "        matches,new_doc_nlp=get_text_position(txt_nlp=new_doc_nlp,position_flag=1)  # pick up '</span>' to end source\n",
    "        if len(matches) > 0:\n",
    "            source_end=matches[0][1]\n",
    "\n",
    "        if new_doc_nlp==[]:\n",
    "            continue\n",
    "\n",
    "    # #End of Option A or B Code: At this stage - we have new_doc_nlp, and source and target start and stops        \n",
    "\n",
    "    if new_doc_nlp is not None:\n",
    "        indra_df_new.loc[i,\"annotation_text\"] = new_doc_nlp.text\n",
    "        indra_df_new.loc[i,\"source_start\"] = source_start\n",
    "        indra_df_new.loc[i,\"source_end\"] = source_end\n",
    "        indra_df_new.loc[i,\"target_start\"] = target_start\n",
    "        indra_df_new.loc[i,\"target_end\"] = target_end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indra_df_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indra_df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check example - at row 22 \n",
    "#nlp.tokenizer.explain(indra_df_new.annotation_text[3])\n",
    "\n",
    "#nlp(indra_df_new.Evidence[22])\n",
    "start=indra_df_new.source_start[22]\n",
    "end=indra_df_new.source_end[23]\n",
    "nlp(indra_df_new['annotation_text'][22])[start:end]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#nlp(indra_df_new.Evidence[22])\n",
    "start=indra_df_new.target_start[22]\n",
    "end=indra_df_new.target_end[22]\n",
    "nlp(indra_df_new['annotation_text'][22])[start:end]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indra_df_new['Evidence'][22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indra_df_new['Text_NLP'][22]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indra_df.to_csv(\"indra_covid_toy_dataset_raw_evidence_high_belief.csv\",index=False,sep=\"\\t\",header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt=indra_df_new['Text_NLP'][22]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt=txt.replace(\"</span>\", \" </span> \") # so tokenizer can split the makrker of the source/target span into separate token\n",
    "txt_nlp=nlp(txt)\n",
    "# Two cases - source appears first, target appears first. \n",
    "matches,new_doc_nlp=get_text_position(txt_nlp=txt_nlp,position_flag=0) # source start\n",
    "matches,new_doc_nlp1=get_text_position(txt_nlp=new_doc_nlp,position_flag=1) # source start\n",
    "matches,new_doc_nlp2=get_text_position(txt_nlp=new_doc_nlp1,position_flag=2) # source start\n",
    "matches,new_doc_nlp3=get_text_position(txt_nlp=new_doc_nlp2,position_flag=3) # source start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_doc_nlp3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD CODE BELOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach A - Generate Triples\n",
    "\n",
    "One approach to generating a toy dataset is to generate triples. \n",
    "Triples can be used to generate knowledge graph embeddings. \n",
    "They also contain grounded source and target identifiers, as well as details relation descriptions. \n",
    "\n",
    "This is not obtained using Approach B - Generate Raw Data with Evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pybel_graph=pickle.load(open( \"pybel_graph.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pybel.io.tsv.api\n",
    "\n",
    "triples=pybel.io.tsv.api.get_triples(pybel_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "triples = np.array(triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triples_df=pd.DataFrame(triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triples_df.to_csv(\"indra_covid_toy_dataset_triples.csv\",index=False,sep=\"\\t\",header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches # position is matches[1] (token start)\n",
    "source_start=matches[0][1]\n",
    "source_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_doc_nlp[5] # position of matches\n",
    "#nlp.tokenizer.explain(new_doc_nlp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        matches,new_doc_nlp=get_text_position(txt_nlp=new_doc_nlp,position_flag=1)  # pick up '</span>' to end source\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now going to find END of source\n",
    "def get_source_end(txt_nlp):\n",
    "    \n",
    "    matcher = Matcher(nlp.vocab, validate=True)\n",
    "\n",
    "    nlp_doc = new_doc_nlp \n",
    "    new_doc = new_doc_nlp.text\n",
    "\n",
    "    names = []\n",
    "\n",
    "    #pattern = [{'POS': 'PROPN'}, {'POS': 'PROPN'}] \n",
    "    pattern = [{\"TEXT\": {\"REGEX\": \"<\"}}, {\"TEXT\": \"/span\"}, {\"TEXT\": \">\"}]\n",
    "    #pattern = [{\"TEXT\": {\"REGEX\": \"<\"}}]\n",
    "    #{\"TEXT\": {\"REGEX\": \"<\"}\n",
    "\n",
    "    matcher.add('end_source', None, pattern) \n",
    "    matches = matcher(nlp_doc) \n",
    "\n",
    "    for match_id, start, end in matches[0:1]: # just replacing first \"</span>\". Not replacing the end of the target for now. \n",
    "        span = nlp_doc[start:end] \n",
    "        names.append(span.text) \n",
    "\n",
    "    for name in names: \n",
    "        new_doc = new_doc.replace(name,'',1) # only replace first occurence\n",
    "        new_doc = new_doc.replace('  ',' ') # replace double whitespace with one whitespace\n",
    "        new_doc_nlp=nlp(new_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "source_end=matches[0][1] # assume only one element in matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evidence_nlp[source_start:source_end] # good pi\n",
    "#nlp.tokenizer.explain(new_doc_nlp.text)  # there is a \"blank token in here that doesnt get shown\"\n",
    "\n",
    "new_doc_nlp[3]\n",
    "#evidence_nlp[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now for target \n",
    "#nlp.tokenizer.explain(new_doc_nlp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher\n",
    "matcher = Matcher(nlp.vocab, validate=True)\n",
    "\n",
    "nlp_doc = new_doc_nlp\n",
    "new_doc = new_doc_nlp.text\n",
    "\n",
    "names = []\n",
    "pattern = [{\"TEXT\": {\"REGEX\": \"<\"}}, {\"TEXT\": \"span\"}, {\"TEXT\": \"class=\\\"badge\"}, {\"TEXT\": \"badge-object\\\"\"},{\"TEXT\": {\"REGEX\": \">\"}}]\n",
    "\n",
    "matcher.add('target_start', None, pattern) \n",
    "matches = matcher(nlp_doc) \n",
    "\n",
    "for match_id, start, end in matches: \n",
    "    span = nlp_doc[start:end] \n",
    "    names.append(span.text) \n",
    "\n",
    "for name in names: \n",
    "    new_doc = new_doc.replace(name,'')\n",
    "    new_doc_nlp=nlp(new_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_start=matches[0][1]  # subtract 1, because first match of \"<\" is treated as prefix, not a token\n",
    "target_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_doc_nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now going to find END of target\n",
    "matcher = Matcher(nlp.vocab, validate=True)\n",
    "\n",
    "nlp_doc = new_doc_nlp \n",
    "new_doc = new_doc_nlp.text\n",
    "\n",
    "names = []\n",
    "\n",
    "#pattern = [{'POS': 'PROPN'}, {'POS': 'PROPN'}] \n",
    "pattern = [{\"TEXT\": {\"REGEX\": \"<\"}}, {\"TEXT\": \"/span\"}, {\"TEXT\": \">\"}]\n",
    "#pattern = [{\"TEXT\": {\"REGEX\": \"<\"}}]\n",
    "#{\"TEXT\": {\"REGEX\": \"<\"}\n",
    "\n",
    "matcher.add('end_source', None, pattern) \n",
    "matches = matcher(nlp_doc) \n",
    "\n",
    "for match_id, start, end in matches[0:1]: # just replacing first \"</span>\". Not replacing the end of the target for now. \n",
    "    span = nlp_doc[start:end] \n",
    "    names.append(span.text) \n",
    "\n",
    "for name in names: \n",
    "    new_doc = new_doc.replace(name,'')\n",
    "    new_doc = new_doc.replace('  ',' ')\n",
    "    new_doc_nlp=nlp(new_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_end=matches[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evidence_nlp[target_start:target_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "#pattern = [{\"LOWER\": \"\\<span class=\\\"badge badge-subject\\\"\\>\"}]\n",
    "pattern = [{\"LOWER\": \"\\<\"}, {\"LOWER\": \"span\"}, {\"LOWER\": \"\\\"badge\"}]\n",
    "pattern = [{\"LOWER\": \"\\<\"}]\n",
    "\n",
    "matcher.add(\"HelloWorld\", None, pattern)\n",
    "doc = nlp(\"hello world!\")\n",
    "matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{\"LOWER\": \"hello\"}, {\"LOWER\": \"world\"}]\n",
    "matcher.add(\"HelloWorld\", None, pattern)\n",
    "doc = nlp(\"hello world!\")\n",
    "matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##OLD CODE\n",
    "# get source end \n",
    "        if new_doc_nlp==[]:\n",
    "            continue\n",
    "            \n",
    "        #  Sometimes object (target) appears before subject (source\n",
    "        # To ensure we match the right '</span>' marking end of the source (not the target)\n",
    "        # just pass in text from source start until the end of the text. \n",
    "        # If src before trgt, then first '</span>' is replaced withut a problem\n",
    "        # If trgt before src, then we cut out this first part of the sentnce, so wont impact the target end '</span>' marker\n",
    "        new_doc_nlp_end=new_doc_nlp[source_start:len(new_doc_nlp.text)]\n",
    "        matches,new_doc_nlp_end=get_text_position(txt_nlp=new_doc_nlp_end,position_flag=1)\n",
    "\n",
    "        # now, need to piece together original doc, + returned doc..\n",
    "        if new_doc_nlp_end==[]:\n",
    "            continue\n",
    "\n",
    "        new_doc_nlp1=nlp(new_doc_nlp[0:source_start].text + new_doc_nlp_end.text)\n",
    "\n",
    "        if len(matches) > 0:\n",
    "            source_end=source_start+matches[0][1] # need to offset the matches position by location of source start\n",
    "\n",
    "        # get target start\n",
    "        #print(\"before target start\")\n",
    "        #print(new_doc_nlp)\n",
    "        if new_doc_nlp1==[]:\n",
    "            continue\n",
    "        matches,new_doc_nlp=get_text_position(txt_nlp=new_doc_nlp1,position_flag=2) # get target start\n",
    "        if len(matches) > 0:\n",
    "            target_start=matches[0][1]\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to add triples - read in api.py module and use to_triple\n",
    "#https://github.com/pybel/pybel/blob/master/src/pybel/io/triples/api.py\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
