{"cells":[{"metadata":{"id":"OU0Z5xhIfpBM"},"cell_type":"markdown","source":"# Training Roberta for contradiction classification\n[Code based on this](https://www.kaggle.com/xhlulu/jigsaw-tpu-xlm-roberta).\nOur goal is to train a binary classification model to determine if a pair of drug-treatment sentences contain any contradiction.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"run_type='save' #save/load\nmethod = '2' #1/2 - defines how to use manconcorpus\nmancon_data_to_use = 'all' #all/equal - defines how many trainings pairs to use from mancon corpus\nmultinli_data_to_use = 35000 #0/number- 0 implies all, defines how many trainings pairs per class to use from multinli corpus\nmodel_name = 'allenai/biobert-roberta-base' #\"allenai/biobert-roberta-base\"/\"deepset/covid_bert_base\"","execution_count":null,"outputs":[]},{"metadata":{"id":"T31PW4gvezWW","trusted":true},"cell_type":"code","source":"#!pip install transformers","execution_count":null,"outputs":[]},{"metadata":{"id":"ahkR-QKuer2w","trusted":true},"cell_type":"code","source":"import os\nimport shutil\nimport numpy as np\nimport pandas as pd\nimport xml.etree.ElementTree as et \nfrom itertools import permutations\n\nfrom keras.utils import np_utils\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Dense, Input\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nimport transformers\nfrom transformers import AutoModel\nfrom transformers import TFAutoModel, AutoTokenizer, AutoModelWithLMHead\nfrom tqdm.notebook import tqdm\nfrom tokenizers import Tokenizer, models, pre_tokenizers, decoders, processors\nimport tensorflow.keras.backend as K\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix\nfrom tensorflow.keras.callbacks import EarlyStopping\nimport pickle","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load the MultiNLI train data set for fine-tuning","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"multinli_data = pd.read_csv('/kaggle/input/multinli/multinli_1.0_train.txt', sep='\\t', error_bad_lines=False)\nmultinli_test_data = pd.read_csv('/kaggle/input/multinli-dev/multinli_1.0_dev_matched.txt', sep='\\t', error_bad_lines=False)\n\nmultinli_data['gold_label'] = [2 if l=='contradiction' else 1 if l=='entailment' else 0 for l in multinli_data.gold_label]\nmultinli_test_data['gold_label'] = [2 if l=='contradiction' else 1 if l=='entailment' else 0 for l in multinli_test_data.gold_label]\n\nif multinli_data_to_use!=0:\n        temp = multinli_data[multinli_data.gold_label==2].append(multinli_data[multinli_data.gold_label==1].head(multinli_data_to_use)).reset_index(drop=True)\n        multinli_data = temp.append(multinli_data[multinli_data.gold_label==0].head(multinli_data_to_use)).reset_index(drop=True)\n\nx_train = '[CLS]'+multinli_data.sentence1+'[SEP]'+multinli_data.sentence2\nx_test = '[CLS]'+multinli_test_data.sentence1+'[SEP]'+multinli_test_data.sentence2\ny_train = np_utils.to_categorical(multinli_data.gold_label)\ny_test = np_utils.to_categorical(multinli_test_data.gold_label)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load the ManConCorpus and split into train and test set for fine-tuning","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Method 1 - Extract yes/no answer pairs to same question as contradiction","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"if method=='1':\n    xtree = et.parse('/kaggle/input/manconcorpus/ManConCorpus.xml')\n    xroot = xtree.getroot() \n\n    manconcorpus_data = pd.DataFrame(columns = ['claim','assertion','question'])\n\n    for node in xroot:\n        for claim in node.findall('CLAIM'):\n            manconcorpus_data = manconcorpus_data.append({'claim':claim.text,\\\n                                                        'assertion':claim.attrib.get('ASSERTION'),\\\n                                                        'question':claim.attrib.get('QUESTION')},\n                                                         ignore_index=True)\n    print(len(manconcorpus_data))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if run_type=='save' and method=='1':\n    questions = list(set(manconcorpus_data.question))\n    con = pd.DataFrame(columns=['claim1','claim2','label'])\n    ent = pd.DataFrame(columns=['claim1','claim2','label'])\n\n    for q in questions:\n        claim_yes = pd.DataFrame(manconcorpus_data.loc[(manconcorpus_data.question==q) & (manconcorpus_data.assertion=='YS'),'claim'])\n        claim_no = pd.DataFrame(manconcorpus_data.loc[(manconcorpus_data.question==q) & (manconcorpus_data.assertion=='NO'),'claim'])\n        temp = claim_yes.assign(key=1).merge(claim_no.assign(key=1), on='key').drop('key', 1)\n        temp1 = temp.rename(columns={'claim_x':'claim1','claim_y':'claim2'})\n        con = con.append(temp1)\n        #Swap claim1 & claim2 to generate more examples. This will handle directionality during fine-tuning.\n        temp2 = temp.rename(columns={'claim_x':'claim2','claim_y':'claim1'})\n        con = con.append(temp2)\n        con['label'] = 1   \n        con.drop_duplicates(inplace=True)\n\n        for i,j in list(permutations(claim_yes.index, 2)):\n            ent = ent.append({'claim1':claim_yes.claim[i],\\\n                        'claim2':claim_yes.claim[j],\\\n                        'label':0},\\\n                       ignore_index=True)\n\n        for i,j in list(permutations(claim_no.index, 2)):\n            ent = ent.append({'claim1':claim_no.claim[i],\\\n                        'claim2':claim_no.claim[j],\\\n                        'label':0},\\\n                       ignore_index=True)\n\n    transfer_data = pd.concat([con,ent]).reset_index(drop=True)\n    transfer_data['label'] = transfer_data.label.astype('float')\n    print(len(con))\n    print(len(ent))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if run_type=='save' and method=='1':\n    x_train_2,x_test_2,y_train_2,y_test_2=train_test_split('[CLS]'+transfer_data.claim1+'[SEP]'+transfer_data.claim2,transfer_data['label'],test_size=0.2)\n    print(y_train_2.sum())\n    print(y_test_2.sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Method 2 - Adding claims from different questions as neutral","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"if run_type=='save' and method=='2':\n    transfer_data = pd.read_csv('/kaggle/input/manconcorpus-sent-pairs/manconcorpus_sent_pairs_200516.tsv', sep ='\\t')\n    transfer_data['label'] = [2 if l=='contradiction' else 1 if l=='entailment' else 0 for l in transfer_data.label]\n    transfer_data['label'] = transfer_data.label.astype('float')\n    print(len(transfer_data[transfer_data.label==2]))\n    print(len(transfer_data[transfer_data.label==1]))\n    print(len(transfer_data[transfer_data.label==0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if run_type=='save' and method=='2':\n    if mancon_data_to_use=='equal':\n        temp = transfer_data[transfer_data.label==2].append(transfer_data[transfer_data.label==1].head(1000)).reset_index(drop=True)\n        transfer_data = temp.append(transfer_data[transfer_data.label==0].head(1000)).reset_index(drop=True)\n    print(len(transfer_data[transfer_data.label==2]))\n    print(len(transfer_data[transfer_data.label==1]))\n    print(len(transfer_data[transfer_data.label==0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if run_type=='save' and method=='2':\n    x_train_2,x_test_2,y_train_2,y_test_2=train_test_split('[CLS]'+transfer_data.text_a+'[SEP]'+transfer_data.text_b,transfer_data['label'],test_size=0.2)\n    print(len(y_train_2[transfer_data.label==2]))\n    print(len(y_train_2[transfer_data.label==1]))\n    print(len(y_train_2[transfer_data.label==0]))\n    print(len(y_test_2[transfer_data.label==2]))\n    print(len(y_test_2[transfer_data.label==1]))\n    print(len(y_test_2[transfer_data.label==0]))\n    y_train_2 = np_utils.to_categorical(y_train_2)\n    y_test_2 = np_utils.to_categorical(y_test_2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Method 3 - Use PICO format questions (i.e. original structure of ManConCorpus)","execution_count":null},{"metadata":{"id":"Nwmt1WIRqRI4","trusted":true},"cell_type":"code","source":"if run_type=='save' and method=='3':\n    x_train_2,x_test_2,y_train_2,y_test_2=train_test_split('[CLS]'+manconcorpus_data.question+'[SEP]'+manconcorpus_data.claim1,manconcorpus_data['assertion'],test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Fine-Tuning BioBERT","execution_count":null},{"metadata":{"id":"dIRFuE8YF7kw","trusted":true},"cell_type":"code","source":"def regular_encode(texts, tokenizer, maxlen=512):\n    \"\"\" Function to encode many sentences\"\"\"\n    enc_di = tokenizer.batch_encode_plus(\n        texts, \n        return_attention_masks=False, \n        return_token_type_ids=False,\n        pad_to_max_length=True,\n        max_length=maxlen,\n        sep_token='[SEP]'\n    )\n    return np.array(enc_di['input_ids'])","execution_count":null,"outputs":[]},{"metadata":{"id":"_E3orumJF8qM","trusted":true},"cell_type":"code","source":"def build_model(transformer, max_len=512):\n    \"\"\"\n    Require a transformer of type TFAutoBert\n    https://www.kaggle.com/xhlulu/jigsaw-tpu-distilbert-with-huggingface-and-keras\n    \"\"\"\n    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n    sequence_output = transformer(input_word_ids)[0]\n    cls_token = sequence_output[:, 0, :]\n    if method=='1':\n        out = Dense(1, activation='sigmoid', name='sigmoid')(cls_token)\n    if method=='2':\n        out = Dense(3, activation='softmax', name='softmax')(cls_token)\n    model = Model(inputs=input_word_ids, outputs=out)\n    if method=='1':\n        model.compile(Adam(lr=1e-6), loss='binary_crossentropy', metrics=[tf.keras.metrics.Recall(), tf.keras.metrics.Precision(), 'accuracy'])\n    if method=='2':\n        model.compile(Adam(lr=1e-6), loss='categorical_crossentropy', metrics=[tf.keras.metrics.Recall(), tf.keras.metrics.Precision(), tf.keras.metrics.CategoricalAccuracy()])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"id":"rwS2xpcnEqjE","trusted":true},"cell_type":"code","source":"if run_type=='save':\n    print(int(int(x_train.str.len().max())))\n    print(int(x_train.str.len().median()))\n    print(int(int(x_train_2.str.len().max())))\n    print(int(x_train_2.str.len().median()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Configuration params\nEPOCHS = 3\nMAX_LEN = 512\nBATCH_SIZE = 32","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drug_names = pd.read_csv('/kaggle/input/drugnames/DrugNames.txt',header=None)\ndrug_names = list(drug_names[0])\nprint('Full list of drugs:',len(drug_names))\nif method=='1':\n    text = ' '.join(list(set(transfer_data.claim1)))\nif method=='2':\n    text = ' '.join(list(set(transfer_data.text_a)))\ndrug_names = [drug for drug in drug_names if drug in text]\nprint('List of drugs in training & testing corpus:',len(drug_names))\nvirus_names = pd.read_csv('/kaggle/input/virus-words/virus_words.txt',header=None)\nvirus_names = list(virus_names[0])","execution_count":null,"outputs":[]},{"metadata":{"id":"a1fNO8q0GVSG","outputId":"badb5a8a-027b-49ee-f8db-50a3fec7e014","trusted":true},"cell_type":"code","source":"if model_name == 'deepset/covid_bert_base':\n    MODEL = \"deepset/covid_bert_base\"\nelse:\n    MODEL = \"allenai/biomed_roberta_base\"\n\n# First load the real tokenizer\ntokenizer = AutoTokenizer.from_pretrained(MODEL)\ntokenizer.add_tokens(drug_names+virus_names)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(tokenizer)","execution_count":null,"outputs":[]},{"metadata":{"id":"qLkUU042Fod7","outputId":"78560238-e9b3-4966-d354-eec35d196fb3","trusted":true},"cell_type":"code","source":"%%time\nif run_type=='save':\n    x_train_str = []\n    for x in x_train:\n        x_train_str.append(str(x))\n\n    x_test_str = []\n    for x in x_test:\n        x_test_str.append(str(x))\n    \n    x_train = regular_encode(x_train_str, tokenizer, maxlen=MAX_LEN)\n    x_test = regular_encode(x_test_str, tokenizer, maxlen=MAX_LEN)\n    \n    x_train_2 = regular_encode(x_train_2.values, tokenizer, maxlen=MAX_LEN)\n    x_test_2 = regular_encode(x_test_2.values, tokenizer, maxlen=MAX_LEN)","execution_count":null,"outputs":[]},{"metadata":{"id":"voqCyuCfGZ5-","trusted":true},"cell_type":"code","source":"es = EarlyStopping(monitor='val_accuracy', \n                    min_delta=0.001, \n                    patience=3,\n                    verbose=1, \n                    mode='max', \n                    restore_best_weights=True)","execution_count":null,"outputs":[]},{"metadata":{"id":"er5WQmW_c2jU","outputId":"9ca03cb8-0a72-4bf5-df2e-edd51ae9bd46","trusted":true},"cell_type":"code","source":"# !pip install wandb\n# !wandb login\n# import wandb\n# from wandb.keras import WandbCallback\n# wandb.init(project=\"vt-relation-extract\", sync_tensorboard=True)","execution_count":null,"outputs":[]},{"metadata":{"id":"EyCPnB1NGfmX","outputId":"e1e17dbd-fe36-47e3-89c0-6d44fc1e0038","trusted":true},"cell_type":"code","source":"if run_type=='save':\n    strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())\n    if model_name == 'deepset/covid_bert_base':\n        model = AutoModelWithLMHead.from_pretrained(\"deepset/covid_bert_base\")\n        model.resize_token_embeddings(len(tokenizer))\n        !mkdir covid_bert_base\n        model.save_pretrained(\"covid_bert_base\")\n        with strategy.scope():\n          model = TFAutoModel.from_pretrained(\"covid_bert_base\", from_pt=True)\n          #model.resize_token_embeddings(len(tokenizer))\n          model = build_model(model)\n    else:\n        model = AutoModel.from_pretrained(\"allenai/biomed_roberta_base\")\n        model.resize_token_embeddings(len(tokenizer))\n        !mkdir biomed_roberta_base\n        model.save_pretrained(\"biomed_roberta_base\")\n        with strategy.scope():\n          model = TFAutoModel.from_pretrained(\"biomed_roberta_base\", from_pt=True)\n          #model.resize_token_embeddings(len(tokenizer))\n          model = build_model(model)\n    BATCH_SIZE = 2 * strategy.num_replicas_in_sync","execution_count":null,"outputs":[]},{"metadata":{"id":"7R5n4eZqeMg_","outputId":"e3825c20-d8d9-4697-b06a-5f9d609a7634","trusted":true},"cell_type":"code","source":"if run_type=='save':\n    model.summary()","execution_count":null,"outputs":[]},{"metadata":{"id":"JhF7YPBiF0xX","outputId":"07095a7d-1c41-41e7-b25d-27619516772b","trusted":true},"cell_type":"code","source":"# Fine tune on MultiNLI\n\nif run_type=='save':\n    train_history = model.fit(\n                        x_train, y_train,\n                        batch_size = BATCH_SIZE,\n                        validation_data=(x_test, y_test),\n                        #callbacks=[es, WandbCallback()],\n                        callbacks=[es],\n                        epochs=EPOCHS\n                        )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fine tune on Manconcorpus\n\nif run_type=='save':\n    train_history = model.fit(\n                        x_train_2, y_train_2,\n                        batch_size = BATCH_SIZE,\n                        validation_data=(x_test_2, y_test_2),\n                        #callbacks=[es, WandbCallback()],\n                        callbacks=[es],\n                        epochs=EPOCHS\n                        )","execution_count":null,"outputs":[]},{"metadata":{"id":"O0o0O9JeQX8_"},"cell_type":"markdown","source":"### Saving/Exporting\nA model isn't useful if it cannot be used in a production pipeline.","execution_count":null},{"metadata":{"id":"ijQgTmZQSpJf","outputId":"2f5d3a88-c126-4ebd-e0f6-d22dda7184e6","trusted":true},"cell_type":"code","source":"# from google.colab import auth\n# from datetime import datetime\n# auth.authenticate_user()\n# !gsutil cp -r best_epoch_roberta gs://coronaviruspublicdata/temp_data/snapshots","execution_count":null,"outputs":[]},{"metadata":{"id":"apHHDn_jlDaL","outputId":"d40a5007-fcba-4768-b96b-a40c8b0e2fad","trusted":true},"cell_type":"code","source":"#import pickle \n#save model, input: sentence, output: binary\n#pickle.dump(model, open( \"bioERT_model1.pickle\", \"wb\" ) )\n# !gsutil cp model.pickle gs://coronaviruspublicdata/model.pickle","execution_count":null,"outputs":[]},{"metadata":{"id":"Wk30_Bog9ng7","outputId":"90d8efde-ef5b-4931-f98f-e4f81703aee3","trusted":true},"cell_type":"code","source":"def save_model(model, transformer_dir='transformer'):\n    \"\"\"\n    Special function to save a keras model that uses a transformer layer\n    \"\"\"\n    transformer = model.layers[1]\n    !mkdir transformer\n    transformer.save_pretrained(transformer_dir)\n    sigmoid = model.get_layer(index=3).get_weights()\n    pickle.dump(sigmoid, open('sigmoid.pickle', 'wb'))\n\ndef load_model(pickle_path, transformer_dir='transformer', max_len=512):\n    \"\"\"\n    Special function to load a keras model that uses a transformer layer\n    \"\"\"\n    transformer = TFAutoModel.from_pretrained(transformer_dir)\n    model = build_model(transformer, max_len=max_len)\n    sigmoid = pickle.load(open(pickle_path, 'rb'))\n    if method=='1':\n        model.get_layer('sigmoid').set_weights(sigmoid)\n    if method=='2':\n        model.get_layer('softmax').set_weights(sigmoid)\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# if run_type=='save':\n#     save_model(model)\n#     shutil.make_archive('biobert_output', 'zip', '/kaggle/working/')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if run_type=='load':\n    model = load_model(\"/kaggle/input/biobertmodel2sigmoid/sigmoid.pickle\", \"/kaggle/input/biobertmodel2transformer\")","execution_count":null,"outputs":[]},{"metadata":{"id":"NSJWuoSxNhLo","outputId":"d363953f-561a-4088-e67f-ac7bdbff73a5","trusted":true},"cell_type":"code","source":"# model.summary()\n# model.get_layer(index=3)","execution_count":null,"outputs":[]},{"metadata":{"id":"NPz93NynbP5F","outputId":"eba1eccd-676f-4ea1-a1e6-0c4a243b32c1","trusted":true},"cell_type":"code","source":"# !gsutil cp -r transformer3 gs://coronaviruspublicdata/re_final_best2/s\n# !gsutil cp sigmoid3.pickle gs://coronaviruspublicdata/re_final_best2/s","execution_count":null,"outputs":[]},{"metadata":{"id":"AJEn0hBdQGHD"},"cell_type":"markdown","source":"### Qualitative Evaluation\nWe will now qualitatively look at a few examples.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"output_data = pd.read_excel('/kaggle/input/drug-individual-claims-similarity-annotated/drug_individual_claims_similarity_annotated.xlsx',sheet_name='drug_individual_claims_similari')\noutput_data = output_data.dropna().reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ls = []\nfor i in range(len(output_data)):\n    ls.append(str('[CLS]'+output_data.loc[i,'text1']+'[SEP]'+output_data.loc[i,'text2']))\n    \ntest_example = regular_encode(ls, tokenizer, maxlen=MAX_LEN)\npredictions = model.predict(test_example)\nif method=='1':\n    output_data['BioBERT_Prediction'] = [p[0] for p in predictions]\nif method=='2':\n    output_data['BioBERT_Prediction_con'] = [p[0] for p in predictions]\n    output_data['BioBERT_Prediction_ent'] = [p[1] for p in predictions]\n    output_data['BioBERT_Prediction_neu'] = [p[2] for p in predictions]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(output_data))\nprint(len(output_data.loc[output_data.annotation=='contradiction',:]))\nprint(len(output_data.loc[output_data.annotation=='entailment',:]))\nprint(len(output_data.loc[output_data.annotation=='neutral',:]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if method=='1':\n    print(max(output_data.BioBERT_Prediction))\nif method=='2':\n    print(max(output_data.BioBERT_Prediction_con))\n    print(max(output_data.BioBERT_Prediction_ent))\n    print(max(output_data.BioBERT_Prediction_neu))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if method=='1':\n    output_data['label'] = [1 if a=='contradiction' else 0 for a in output_data.annotation]\n    output_data['BioBERT_Prediction_class'] = [1 if p>=0.375 else 0 for p in output_data.BioBERT_Prediction]\n    \n    print('Overall accuracy: '\\\n      + str(accuracy_score(output_data['label'], output_data['BioBERT_Prediction_class'] )))\n    print('Precision: '\\\n          + str(precision_score(output_data['label'], output_data['BioBERT_Prediction_class'] )))\n    print('Recall: '\\\n          + str(recall_score(output_data['label'], output_data['BioBERT_Prediction_class'] )))\n    print('F1 score: '\\\n          + str(f1_score(output_data['label'], output_data['BioBERT_Prediction_class'] )))\n\nif method=='2':\n    output_data['label'] = output_data.annotation\n    output_data['BioBERT_Prediction_class'] = output_data[['BioBERT_Prediction_con','BioBERT_Prediction_ent','BioBERT_Prediction_neu']].idxmax(axis=1)\n    output_data['BioBERT_Prediction_class'].replace(to_replace={'BioBERT_Prediction_con':'contradiction','BioBERT_Prediction_ent':'entailment','BioBERT_Prediction_neu':'neutral'}\\\n                                                   ,inplace=True)\n    \n    print('Overall accuracy: '\\\n      + str(accuracy_score(output_data['label'], output_data['BioBERT_Prediction_class'] )))\n    print('Precision: '\\\n          + str(precision_score(output_data['label'], output_data['BioBERT_Prediction_class'], average = None)))\n    print('Recall: '\\\n          + str(recall_score(output_data['label'], output_data['BioBERT_Prediction_class'], average = None)))\n    print('F1 score: '\\\n          + str(f1_score(output_data['label'], output_data['BioBERT_Prediction_class'], average = None)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output_data.to_csv('bioBERT_Output.csv',header=True)","execution_count":null,"outputs":[]},{"metadata":{"id":"UPkms0lPZq-r"},"cell_type":"markdown","source":"### Tests for RAM usage\nBasic check to determine how much RAM is available.","execution_count":null},{"metadata":{"id":"fhTaBLOX9oU9","outputId":"ce782b67-6934-4e95-8bcc-6fb8b8fd1f46","trusted":true},"cell_type":"code","source":"# !ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n# !pip install gputil\n# !pip install psutil\n# !pip install humanize\n# import psutil\n# import humanize\n# import os\n# import GPUtil as GPU\n# GPUs = GPU.getGPUs()\n# # XXX: only one GPU on Colab and isnâ€™t guaranteed\n# gpu = GPUs[0]\n# def printm():\n#  process = psutil.Process(os.getpid())\n#  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n#  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n# printm()","execution_count":null,"outputs":[]},{"metadata":{"id":"GB3ICTE4agSR","outputId":"e0930843-35c8-42e8-c6c2-9ecaf808e35f","trusted":true},"cell_type":"code","source":"# from google.colab import auth\n# from datetime import datetime\n# auth.authenticate_user()\n","execution_count":null,"outputs":[]},{"metadata":{"id":"REBWSm-5a5GW","trusted":true},"cell_type":"code","source":"# !gsutil cp -r transformer gs://coronaviruspublicdata/re_snapshot/4_13_2020\n# !gsutil cp sigmoid.pickle gs://coronaviruspublicdata/re_snapshot/4_13_2020","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}